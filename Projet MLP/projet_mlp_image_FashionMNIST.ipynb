{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 2.3.1\n",
      "No GPU found, using CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print('Using GPU, device name:', torch.cuda.get_device_name(0))\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('No GPU found, using CPU instead.')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du dataset d'entraînement: 48000\n",
      "Taille du dataset de test: 12000\n"
     ]
    }
   ],
   "source": [
    "# Définir les transformations pour les données\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),  # Redimensionner les images à 224x224\n",
    "    transforms.ToTensor(),  # Convertir les images en tenseurs PyTorch\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normaliser les images (FashionMNIST est en niveaux de gris)\n",
    "])\n",
    "\n",
    "# Télécharger et charger le jeu de données FashionMNIST\n",
    "dataset = datasets.FashionMNIST(root='./data', \n",
    "                                train=True, \n",
    "                                transform=transform, \n",
    "                                download=True)\n",
    "\n",
    "# Séparer les données en ensemble d'entraînement et de test\n",
    "# Calculer la taille de chaque sous-dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Diviser le dataset en ensemble d'entraînement et de test\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Créer des DataLoader pour les ensembles d'entraînement et de test\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Afficher les tailles des datasets pour vérification\n",
    "print(f'Taille du dataset d\\'entraînement: {len(train_dataset)}')\n",
    "print(f'Taille du dataset de test: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleMLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=20, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=20, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model = SimpleMLP().to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "def correct(output, target):\n",
    "    predicted_digits = output.argmax(1)                            # choisir le chiffre avec la plus grande sortie du réseau\n",
    "    correct_ones = (predicted_digits == target).type(torch.float)  # 1.0 pour correct, 0.0 pour incorrect\n",
    "    return correct_ones.sum().item()                               # compter le nombre de bons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Average loss: 0.604730, accuracy: 79.32%\n",
      "Training epoch: 2\n",
      "Average loss: 0.443107, accuracy: 84.15%\n",
      "Training epoch: 3\n",
      "Average loss: 0.411755, accuracy: 85.31%\n",
      "Training epoch: 4\n",
      "Average loss: 0.391875, accuracy: 85.85%\n",
      "Training epoch: 5\n",
      "Average loss: 0.376635, accuracy: 86.40%\n",
      "Training epoch: 6\n",
      "Average loss: 0.364817, accuracy: 86.88%\n",
      "Training epoch: 7\n",
      "Average loss: 0.356330, accuracy: 87.17%\n",
      "Training epoch: 8\n",
      "Average loss: 0.347272, accuracy: 87.41%\n",
      "Training epoch: 9\n",
      "Average loss: 0.341421, accuracy: 87.66%\n",
      "Training epoch: 10\n",
      "Average loss: 0.334044, accuracy: 87.90%\n"
     ]
    }
   ],
   "source": [
    "def train(data_loader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    num_batches = len(data_loader)\n",
    "    num_items = len(data_loader.dataset)\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for data, target in data_loader:\n",
    "        # Copier les données et les cibles sur le GPU\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Effectuer une passe avant\n",
    "        output = model(data)\n",
    "\n",
    "        # Calculer la perte\n",
    "        loss = criterion(output, target)\n",
    "        total_loss += loss\n",
    "\n",
    "        # Compter le nombre de chiffres corrects\n",
    "        total_correct += correct(output, target)\n",
    "\n",
    "        # Rétropropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    train_loss = total_loss/num_batches\n",
    "    accuracy = total_correct/num_items\n",
    "    print(f\"Average loss: {train_loss:7f}, accuracy: {accuracy:.2%}\")\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Training epoch: {epoch+1}\")\n",
    "    train(train_loader, model, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset accuracy: 86.6%, average loss: 0.382256\n"
     ]
    }
   ],
   "source": [
    "def test(test_loader, model, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    num_batches = len(test_loader)\n",
    "    num_items = len(test_loader.dataset)\n",
    "\n",
    "    test_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # Copier les données et les cibles sur le GPU\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Effectuer une passe avant\n",
    "            output = model(data)\n",
    "\n",
    "            # Calculer la perte\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Compter le nombre de chiffres corrects\n",
    "            total_correct += correct(output, target)\n",
    "\n",
    "    test_loss = test_loss/num_batches\n",
    "    accuracy = total_correct/num_items\n",
    "\n",
    "    print(f\"Testset accuracy: {100*accuracy:>0.1f}%, average loss: {test_loss:>7f}\")\n",
    "\n",
    "test(test_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la matrice de confusion\n",
    "conf_matrix = confusion_matrix(test_y,predict_y)\n",
    "fig, ax = plt.subplots(figsize=(7, 7))  # Adjust the figsize as needed\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
